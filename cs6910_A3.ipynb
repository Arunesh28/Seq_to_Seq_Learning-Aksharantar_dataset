{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# import langdetect\n",
        "# from langdetect import detect\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "_XMtpZKWB6IS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2XFj4FB_8QJ",
        "outputId": "ac2ad086-e506-4512-f7ca-e15fc1496f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/aksharantar_sampled.zip > /dev/null"
      ],
      "metadata": {
        "id": "BvtANBSb_-EJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READING DATA"
      ],
      "metadata": {
        "id": "RjJtGtexp-MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv('aksharantar_sampled/hin/hin_train.csv',header=None)\n",
        "X_train = list(train_data[0])\n",
        "Y_train = list(train_data[1])\n",
        "\n",
        "validation_data=pd.read_csv('aksharantar_sampled/hin/hin_valid.csv',header=None)\n",
        "X_valid = list(validation_data[0])\n",
        "Y_valid = list(validation_data[1])\n",
        "\n",
        "test_data=pd.read_csv('aksharantar_sampled/hin/hin_test.csv',header=None)\n",
        "X_test = list(test_data[0])\n",
        "Y_test = list(test_data[1])"
      ],
      "metadata": {
        "id": "L2B6m1l3CG0z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PROCESSING"
      ],
      "metadata": {
        "id": "fCpYM7uh22Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_hot(char_dict,ch,len_alphabets):\n",
        "  input_index = char_dict[ch]\n",
        "  one_hot_tensor = np.zeros(len_alphabets)\n",
        "  one_hot_tensor[input_index] = 1\n",
        "  return one_hot_tensor.tolist()\n",
        "\n",
        "def data_processing(data,char_dict,len_chrs):\n",
        "  ONE_HOT = []\n",
        "  for word in data :\n",
        "    word = '$' + word + '*'\n",
        "    encoded_word = [get_one_hot(char_dict,i,len_chrs) for i in word]\n",
        "    encoded_word = torch.tensor(encoded_word)\n",
        "    ONE_HOT.append(encoded_word)\n",
        "  return ONE_HOT"
      ],
      "metadata": {
        "id": "SrltDzm5mMwP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ - Start Character \\\\\n",
        "\\* - End Character"
      ],
      "metadata": {
        "id": "Pc1uE0ahwa77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_chrs = '$'\n",
        "for i in range(2304,2432):\n",
        "  tgt_chrs += chr(i)\n",
        "tgt_chrs += '*'\n",
        "tgt_char_dict = {char: i for i, char in enumerate(tgt_chrs)}\n",
        "\n",
        "inp_chrs = '$abcdefghijklmnopqrstuvwxyz*'\n",
        "inp_char_dict = {char: i for i, char in enumerate(inp_chrs)}"
      ],
      "metadata": {
        "id": "ghyHiKPnTIgc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the template to create your dataset for the langauage you want to train on"
      ],
      "metadata": {
        "id": "8RjpAd7KjQz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "start -> unicode of the first character in the language\n",
        "end -> unicode of the last character in the language\n",
        "\n",
        "tgt_chrs = '$'\n",
        "for i in range(start,end):\n",
        "  tgt_chrs += chr(i)\n",
        "tgt_chrs += '*'\n",
        "tgt_char_dict = {char: i for i, char in enumerate(tgt_chrs)}\n",
        "\n",
        "inp_chrs = '$abcdefghijklmnopqrstuvwxyz*'\n",
        "inp_char_dict = {char: i for i, char in enumerate(inp_chrs)}\n",
        "'''"
      ],
      "metadata": {
        "id": "wC_4tPYTizbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are lists of tensors corresponding to each word\n",
        "inp_train = data_processing(X_train,inp_char_dict,len(inp_chrs))\n",
        "tgt_train = data_processing(Y_train,tgt_char_dict,len(tgt_chrs))\n",
        "inp_valid = data_processing(X_valid,inp_char_dict,len(inp_chrs))\n",
        "tgt_valid = data_processing(Y_valid,tgt_char_dict,len(tgt_chrs))\n",
        "inp_test = data_processing(X_test,inp_char_dict,len(inp_chrs))\n",
        "tgt_test = data_processing(Y_test,tgt_char_dict,len(tgt_chrs))"
      ],
      "metadata": {
        "id": "fK9M6b07xDox"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENCODER"
      ],
      "metadata": {
        "id": "NYGk6k9B274a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_layer_size, num_encoder_layers, cell_type, dropout_prob, bidirectional):\n",
        "      super(Encoder, self).__init__()\n",
        "      '''\n",
        "        self.input_size : int\n",
        "        self.hidden_layer_size : int\n",
        "        self.num_encoder_layers : int\n",
        "        self.cell_type : string\n",
        "      '''\n",
        "      self.input_size = input_size\n",
        "      self.hidden_layer_size = hidden_layer_size\n",
        "      self.num_encoder_layers = num_encoder_layers\n",
        "      self.cell_type = cell_type\n",
        "      # self.cells = {'RNN':RNN,'LSTM':LSTM,'GRU':GRU}\n",
        "      self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "      if cell_type == 'RNN':\n",
        "        self.rnn = nn.RNN(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_encoder_layers, nonlinearity = 'relu', dropout = dropout_prob, bidirectional = bidirectional)\n",
        "      elif cell_type == 'LSTM':\n",
        "        self.rnn = nn.LSTM(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_encoder_layers, dropout = dropout_prob, bidirectional = bidirectional)\n",
        "      elif cell_type == 'GRU':\n",
        "        self.rnn = nn.GRU(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_encoder_layers, dropout = dropout_prob, bidirectional = bidirectional)\n",
        "      \n",
        "      self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input, prev_hidden):\n",
        "      embedded = self.embedding(input.to(torch.int64))\n",
        "      embedded = self.dropout(embedded)\n",
        "\n",
        "      # print(embedded.size())\n",
        "\n",
        "      if self.cell_type == 'RNN':\n",
        "        output, hidden = self.rnn(embedded,prev_hidden)\n",
        "      elif self.cell_type == 'LSTM':\n",
        "        output, hidden = self.rnn(embedded,prev_hidden)\n",
        "      elif self.cell_type == 'GRU':\n",
        "        output, hidden = self.rnn(embedded,prev_hidden)\n",
        "\n",
        "      return output,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "      # return torch.zeros(1,1,self.hidden_layer_size)\n",
        "      return torch.zeros(self.num_encoder_layers,self.hidden_layer_size)"
      ],
      "metadata": {
        "id": "6WNDRGpjGs16"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DECODER"
      ],
      "metadata": {
        "id": "5gjv22ej2-cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Decoder\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_size, embedding_size, hidden_layer_size, num_layers, cell_type, dropout_prob, bidirectional):\n",
        "    super(Decoder, self).__init__()\n",
        "    '''\n",
        "      self.output_size : int\n",
        "      self.hidden_layer_size : int\n",
        "      self.num_encoder_layers : int\n",
        "      self.cell_type : string\n",
        "      self.rnn : RNN,LSTM,GRU \n",
        "    '''\n",
        "    self.output_size = output_size\n",
        "    self.hidden_layer_size = hidden_layer_size\n",
        "    self.num_layers = num_layers\n",
        "    self.cell_type = cell_type\n",
        "    # self.cells = {'RNN':RNN,'LSTM':LSTM,'GRU':GRU}\n",
        "    \n",
        "    self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "\n",
        "    if cell_type == 'RNN':\n",
        "      self.rnn = nn.RNN(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_layers, nonlinearity = 'relu', dropout = dropout_prob, bidirectional = bidirectional)\n",
        "    elif cell_type == 'LSTM':\n",
        "      self.rnn = nn.LSTM(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_layers, dropout = dropout_prob, bidirectional = bidirectional)\n",
        "    elif cell_type == 'GRU':\n",
        "      self.rnn = nn.GRU(input_size = embedding_size, hidden_size = hidden_layer_size, num_layers = num_layers, dropout = dropout_prob, bidirectional = bidirectional)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "      \n",
        "  def forward(self, input, prev_hidden):\n",
        "    # input = input.unsqueeze(0)\n",
        "    embedded = self.dropout(self.embedding(input.to(torch.int64)))\n",
        "    # print(embedded.size)\n",
        "    if self.cell_type == 'RNN':\n",
        "      output, hidden = self.rnn(embedded,prev_hidden)\n",
        "    elif self.cell_type == 'LSTM':\n",
        "      output, hidden = self.rnn(embedded,prev_hidden)\n",
        "    elif self.cell_type == 'GRU':\n",
        "      output, hidden = self.rnn(embedded,prev_hidden)\n",
        "    # output = output.squeeze(0)\n",
        "    y_pred = self.fc(output)\n",
        "    return y_pred, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers,self.hidden_layer_size)\n"
      ],
      "metadata": {
        "id": "afYWn2_zLtUn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(inp_train[0][0]))\n",
        "print(len(tgt_train[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYxAvwoDKDUS",
        "outputId": "80aa5df2-165b-4618-b350-de8113860294"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEQ2SEQ"
      ],
      "metadata": {
        "id": "SdVuHQkC3AEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # class seq2seq\n",
        "\n",
        "# class Seq2Seq(nn.Module):\n",
        "#     def __init__(self, encoder, decoder):\n",
        "#       super(Seq2Seq, self).__init__()\n",
        "#       self.encoder = encoder\n",
        "#       self.decoder = decoder\n",
        "        \n",
        "#     def forward(self, input, target, teacher_forcing_ratio):\n",
        "#       # print(input,target)\n",
        "#       # batch_size = len(input)\n",
        "#       target_len = len(target)\n",
        "#       target_vocab_size = self.decoder.output_size\n",
        "      \n",
        "#       output,hidden,cell = self.encoder(input)\n",
        "#       # decoder_hidden = encoder_hidden\n",
        "      \n",
        "#       # decoder_input = torch.ones(batch_size, 1, dtype=torch.long) * SOS_token\n",
        "#       outputs = torch.zeros(batch_size, target_len, target_vocab_size)\n",
        "#       x = target[0]\n",
        "#       # flag = False\n",
        "#       # if np.random.random() < teacher_forcing_ratio:\n",
        "#       #   flag = True\n",
        "\n",
        "#       for t in range(1,target_len):\n",
        "#         output,hidden,cell = self.decoder(x,hidden,cell)\n",
        "#         outputs[t] = output\n",
        "#         best_guess = output.argmax(1)\n",
        "#         x = target[t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "#       # if np.random.random() < teacher_forcing_ratio:\n",
        "#       #     for t in range(1, target_len):\n",
        "#       #         decoder_output, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden)\n",
        "#       #         outputs[:, t, :] = decoder_output.squeeze(1)\n",
        "#       #         decoder_input = target[:, t].unsqueeze(1)\n",
        "#       # else:\n",
        "#       #     for t in range(1, target_len):\n",
        "#       #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "#       #         outputs[:, t, :] = decoder_output.squeeze(1)\n",
        "#       #         _, topi = decoder_output.topk(1)\n",
        "#       #         decoder_input = topi.squeeze().detach().unsqueeze(1)\n",
        "\n",
        "\n",
        "#       return outputs\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, teacher_forcing_ratio):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "      \n",
        "  def forward(self, input, target):\n",
        "    # here input is a word\n",
        "    input_length = input.size()[0]\n",
        "    target_length = target.size()[0]\n",
        "\n",
        "    encoder_hidden = self.encoder.init_hidden()\n",
        "    outputs = ()\n",
        "    for i in range(input_length):\n",
        "      encoder_outputs, encoder_hidden = self.encoder(input[i],encoder_hidden)\n",
        "      outputs = outputs + (encoder_outputs,)\n",
        "    outputs = torch.stack(outputs)\n",
        "\n",
        "    decoder_input = target[0]\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for i in range(1,target_length):\n",
        "      decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "      loss += criterion(decoder_output, target[i].to(torch.long))\n",
        "      decoder_input = target[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "K2kSt-oOLutP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.LongTensor([1,2,3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG954sGgkiKL",
        "outputId": "fc66b8b3-8bae-4507-bfec-7f3b288f2ece"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "OsQc8sWA1V41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "encodertest = Encoder(28,32,10,1,'RNN',0.1,False)\n",
        "decodertest = Decoder(130,32,10,1,'RNN',0.1,False)\n",
        "print(encodertest)\n",
        "\n",
        "criterion_ = nn.CrossEntropyLoss()\n",
        "\n",
        "# print(decodertest)\n",
        "input = inp_train[0]\n",
        "target = tgt_train[0]\n",
        "\n",
        "input_length = input.size()[0]\n",
        "target_length = target.size()[0]\n",
        "\n",
        "encoder_hidden = encodertest.init_hidden()\n",
        "\n",
        "outputs = ()\n",
        "for i in range(input_length):\n",
        "  encoder_outputs, encoder_hidden = encodertest(input[i],encoder_hidden)\n",
        "  outputs = outputs + (encoder_outputs,)\n",
        "outputs = torch.stack(outputs)\n",
        "\n",
        "decoder_input = target[0]\n",
        "decoder_hidden = encoder_hidden\n",
        "loss = 0\n",
        "for i in range(1,target_length):\n",
        "  decoder_output, decoder_hidden = decodertest(decoder_input, decoder_hidden)\n",
        "  loss += criterion_(decoder_output, target[i].to(torch.long))\n",
        "  decoder_input = target[i]\n",
        "loss.backward()\n",
        "\n",
        "# decoder_input = torch.tensor([[]])\n",
        "# decoder_context = \n",
        "# decoder_hidden = encoder_hidden\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRGD-0G73E2k",
        "outputId": "eb1106de-915c-4011-8dff-5420d4af3b14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(28, 32)\n",
            "  (rnn): RNN(32, 10, dropout=0.1)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target[0].to(torch.long))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzLEllsZkBBN",
        "outputId": "16d82c04-8d6d-4932-8ae4-a8ca64a068d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYjTV44Us0qX",
        "outputId": "62ebcea3-2388-424c-d680-b18063f04434"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iESQPB030Aes",
        "outputId": "e6020501-c8d8-4e87-acf6-049e0b22e40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13, 28, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inp_train.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mceh0NkdprV6",
        "outputId": "ce27e8ca-8ca3-4867-f7e9-63a4ebf7a507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_outputs)\n",
        "print(encoder_hidden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tOBzi9pex6A",
        "outputId": "e966ee5a-c634-4430-af44-7e8a480ddf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 1.8855, 0.6622, 0.7420, 1.1964, 0.0000, 0.0000, 1.2684, 0.0000,\n",
            "         2.3074],\n",
            "        [0.0000, 1.5298, 0.8144, 0.4727, 1.2792, 0.0000, 0.0000, 1.3701, 0.0000,\n",
            "         1.7316],\n",
            "        [0.0000, 1.4651, 1.3315, 0.8014, 1.2308, 0.0000, 0.0000, 1.5243, 0.0000,\n",
            "         1.8885],\n",
            "        [0.0000, 0.6418, 1.1225, 0.0316, 1.6798, 0.0516, 0.0913, 0.7559, 0.0000,\n",
            "         1.9943],\n",
            "        [0.0000, 0.7370, 0.6676, 0.2135, 1.6270, 0.0000, 0.0000, 0.7825, 0.0000,\n",
            "         2.3150],\n",
            "        [0.0000, 1.1674, 0.9657, 0.4914, 1.7283, 0.0000, 0.0000, 0.8906, 0.0000,\n",
            "         2.3202],\n",
            "        [0.0000, 1.2428, 1.2997, 0.6932, 1.1392, 0.0000, 0.0000, 1.2331, 0.0000,\n",
            "         2.1465],\n",
            "        [0.0000, 1.6089, 1.2910, 0.5076, 1.0636, 0.0750, 0.0000, 1.2108, 0.0000,\n",
            "         2.0738],\n",
            "        [0.0000, 1.5420, 0.7652, 0.6485, 1.4365, 0.3293, 0.0000, 1.0843, 0.0000,\n",
            "         1.6194],\n",
            "        [0.0000, 1.7897, 1.6257, 0.0000, 1.4942, 0.2314, 0.5316, 0.5735, 0.0000,\n",
            "         1.5075],\n",
            "        [0.0000, 1.6178, 0.9936, 0.5270, 0.9150, 0.0000, 0.0000, 0.9088, 0.0000,\n",
            "         2.7858],\n",
            "        [0.0000, 1.3843, 0.9472, 0.5639, 0.9651, 0.0000, 0.0000, 1.0546, 0.0000,\n",
            "         1.6702],\n",
            "        [0.0000, 1.7141, 1.3576, 0.4488, 1.0130, 0.0000, 0.0000, 1.1965, 0.0102,\n",
            "         2.0196],\n",
            "        [0.0000, 2.1318, 1.0756, 0.2841, 0.5237, 0.3897, 0.0000, 0.5416, 0.0000,\n",
            "         1.9631],\n",
            "        [0.0000, 2.7730, 0.7230, 0.1359, 1.1507, 0.0473, 0.0256, 1.2032, 0.0000,\n",
            "         2.0015],\n",
            "        [0.0000, 1.1910, 1.1247, 0.7190, 1.4011, 0.0000, 0.0000, 1.5167, 0.0000,\n",
            "         1.3800],\n",
            "        [0.0000, 1.4535, 0.8547, 0.0000, 0.6174, 0.3644, 1.2824, 0.7249, 0.0000,\n",
            "         1.1488],\n",
            "        [0.0000, 1.6820, 1.0976, 0.6632, 1.3872, 0.6174, 0.0000, 1.2552, 1.0116,\n",
            "         1.7932],\n",
            "        [0.0000, 1.7255, 1.8819, 1.0533, 0.4239, 0.0000, 0.0000, 1.2911, 0.0000,\n",
            "         1.8304],\n",
            "        [0.0000, 1.5028, 1.1665, 0.7424, 0.8660, 0.2966, 0.0000, 1.6380, 0.0000,\n",
            "         2.0325],\n",
            "        [0.0000, 1.8362, 1.2878, 0.7243, 0.9927, 0.0000, 0.0000, 1.2542, 0.0000,\n",
            "         2.1018],\n",
            "        [0.0000, 1.6412, 0.9515, 0.5327, 1.2915, 0.1376, 0.0000, 1.4371, 0.2828,\n",
            "         1.4923],\n",
            "        [0.0000, 1.8981, 0.9843, 0.1168, 0.4706, 0.0000, 0.0000, 1.5835, 0.1498,\n",
            "         2.2511],\n",
            "        [0.0000, 2.0026, 1.1439, 0.8378, 1.1708, 0.1684, 0.0000, 1.3419, 0.0000,\n",
            "         1.9843],\n",
            "        [0.0000, 1.3873, 0.9212, 0.6739, 0.9858, 0.0000, 0.2003, 1.8828, 0.0000,\n",
            "         1.5127],\n",
            "        [0.0000, 1.6071, 1.2458, 0.6656, 1.0648, 0.1222, 0.0000, 1.5186, 0.0000,\n",
            "         1.9905],\n",
            "        [0.0000, 1.5757, 0.8812, 0.3476, 1.0176, 0.0000, 0.0000, 1.6818, 0.0000,\n",
            "         1.5133],\n",
            "        [0.2834, 0.0000, 0.5427, 1.2995, 0.0000, 0.3404, 0.0000, 0.3458, 0.0000,\n",
            "         0.3780]], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[0.2834, 0.0000, 0.5427, 1.2995, 0.0000, 0.3404, 0.0000, 0.3458, 0.0000,\n",
            "         0.3780]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,criterion):\n",
        "  # Trains once on the whole dataset\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for i in range(len(inp_train)):\n",
        "    input_tensor = inp_train[i]\n",
        "    target_tensor = tgt_train[i]\n",
        "\n",
        "    predictions = model(input_tensor,target_tensor)\n",
        "\n",
        "    loss = criterion(predictions)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss += loss.item()\n",
        "  return loss\n",
        "\n",
        "def train_model(model,learning_rate,epochs):\n",
        "  encoder_optimizer = optim.Adam(model.encoder.parameters(), lr = learning_rate)\n",
        "  decoder_optimizer = optim.Adam(model.decoder.parameters(), lr = learning_rate)\n",
        "  criterion = nn.NLLLoss()\n",
        "  for epoch in range(epochs):\n",
        "    loss = train(model,optimizer,criterion)\n",
        "    print(\"Epoch : %d, Loss : %f\" % (epoch,loss))\n",
        "# def train(model, iterator, optimizer, criterion):\n",
        "#     model.train()\n",
        "#     epoch_loss = 0\n",
        "#     for batch in iterator:\n",
        "#         optimizer.zero_grad()\n",
        "#         predictions = model(batch.text)\n",
        "#         loss = criterion(predictions, batch.label)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         epoch_loss += loss.item()\n",
        "#     return epoch_loss / len(iterator)\n"
      ],
      "metadata": {
        "id": "OYxHfVnivOge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyperparameters\n",
        "input_size = len(inp_train[0][0])\n",
        "embedding_size = 128\n",
        "output_size = len(tgt_train[0][0])\n",
        "hidden_layer_size = 256\n",
        "num_layers = 2\n",
        "cell_type = 'RNN'\n",
        "dropout_prob = 0.2\n",
        "learning_rate = 0.01\n",
        "bidirectional = True\n",
        "epochs = 5\n",
        "\n",
        "encoder = Encoder(input_size, embedding_size, hidden_layer_size, num_layers, cell_type, dropout_prob, bidirectional)\n",
        "decoder = Decoder(output_size, embedding_size, hidden_layer_size, num_layers, cell_type, dropout_prob, bidirectional)\n",
        "model = Seq2Seq(encoder,decoder)\n",
        "# optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "train_model(model,epochs)"
      ],
      "metadata": {
        "id": "BSYSelQ7dG3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "aEoJhJIvNzrP",
        "outputId": "bd191b97-24ca-494c-a258-b79a98ceace5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]]) tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-2be228cfa511>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-b4a46cec3539>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, crierion, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrierion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch : %d, Loss : %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# def train(model, iterator, optimizer, criterion):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-b4a46cec3539>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-54fe2b4fdbe9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;31m# decoder_hidden = encoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-e01b470922cd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    }
  ]
}